# ===============================
# Application
# ===============================
APP_NAME=advanced-rag
APP_ENV=development  # development | staging | production
LOG_LEVEL=INFO
DEBUG_RAG=false
TIMEZONE=UTC

# ===============================
# OpenAI
# ===============================
OPENAI_API_KEY=your_openai_api_key
OPENAI_DEFAULT_MODEL=gpt-4.1-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_TIMEOUT=30
OPENAI_MAX_RETRIES=3

# ===============================
# Anthropic (Claude)
# ===============================
ANTHROPIC_API_KEY=your_anthropic_api_key
ANTHROPIC_DEFAULT_MODEL=claude-3-5-sonnet-20240620
ANTHROPIC_TIMEOUT=30

# ===============================
# Google Gemini
# ===============================
GOOGLE_API_KEY=your_google_api_key
GEMINI_DEFAULT_MODEL=gemini-1.5-pro
GEMINI_TIMEOUT=30

# ===============================
# Mistral
# ===============================
MISTRAL_API_KEY=your_mistral_api_key
MISTRAL_DEFAULT_MODEL=mistral-large-latest
MISTRAL_TIMEOUT=30

# ===============================
# Local / Open-source LLMs
# ===============================
LOCAL_LLM_ENABLED=false
LOCAL_LLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
LOCAL_LLM_DEVICE=cpu  # cpu | cuda
LOCAL_LLM_MAX_TOKENS=2048

# ===============================
# Embeddings
# ===============================
EMBEDDING_PROVIDER=openai  # openai | sentence-transformers
EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
EMBEDDING_BATCH_SIZE=64
EMBEDDING_CACHE_ENABLED=true
EMBEDDING_CACHE_TTL_SECONDS=86400

# ===============================
# Vector Store Selection
# ===============================
VECTOR_STORE=chroma  # chroma | faiss | pinecone

# ===============================
# Chroma (Local)
# ===============================
CHROMA_PERSIST_DIRECTORY=./data/chroma
CHROMA_COLLECTION_TEXT=text_index
CHROMA_COLLECTION_IMAGE=image_index
CHROMA_COLLECTION_AUDIO=audio_index

# ===============================
# FAISS (Local)
# ===============================
FAISS_INDEX_PATH=./data/faiss
FAISS_USE_INNER_PRODUCT=false

# ===============================
# Pinecone
# ===============================
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX_NAME=rag-text-index
PINECONE_DIMENSION=3072
PINECONE_METRIC=cosine
PINECONE_NAMESPACE=default
PINECONE_TIMEOUT=30

# ===============================
# Retrieval Settings
# ===============================
TOP_K_TEXT=5
TOP_K_IMAGE=3
TOP_K_AUDIO=3
USE_MMR=true
MMR_LAMBDA=0.5
RETRIEVAL_CONFIDENCE_THRESHOLD=0.2
MAX_SUB_QUERIES=5

# ===============================
# HyDE / Query Rewriting
# ===============================
ENABLE_HYDE=true
HYDE_MODEL=gpt-4.1-mini
HYDE_MAX_TOKENS=300
HYDE_TIMEOUT=20

# ===============================
# Reranking
# ===============================
ENABLE_RERANKING=false
RERANK_MODEL=gpt-4.1-mini
RERANK_TOP_N=5
RERANK_TIMEOUT=20

# ===============================
# Context Compression
# ===============================
COMPRESSION_MODEL=gpt-4.1-mini
COMPRESSION_MAX_TOKENS=500
MAX_CONTEXT_TOKENS=4000

# ===============================
# Answer Generation
# ===============================
ANSWER_MODEL=gpt-4.1-mini
ANSWER_TEMPERATURE=0.2
ANSWER_TIMEOUT=40

# ===============================
# Safety & Limits
# ===============================
MAX_INPUT_TOKENS=800
MAX_OUTPUT_TOKENS=800
RATE_LIMIT_PER_MINUTE=60
ENABLE_PROMPT_INJECTION_DETECTION=true
ENABLE_CITATION_ENFORCEMENT=true

# ===============================
# Ingestion & Preprocessing
# ===============================
INGESTION_BATCH_SIZE=10
MIN_CHUNK_CHAR_LENGTH=200
MAX_CHUNK_CHAR_LENGTH=2000
OCR_LANGUAGE=eng
TRANSCRIPTION_LANGUAGE=en
TRANSCRIPTION_MODEL=base
LOW_QUALITY_DOC_QUARANTINE=true

# ===============================
# Caching
# ===============================
ENABLE_QUERY_CACHE=true
QUERY_CACHE_TTL_SECONDS=600

# ===============================
# LangGraph / Pipeline
# ===============================
ENABLE_QUERY_CLASSIFICATION=true
GRAPH_MAX_RETRIES=2

# ===============================
# Ambiguity / Clarification
# ===============================
AMBIGUITY_MODEL=gpt-4.1-mini
AMBIGUITY_TIMEOUT=15

# ===============================
# Retrieval Confidence
# ===============================
# Distance threshold below which retrieval is considered confident.
# Values ≈ 0.2–0.4 are typical for cosine distance.
# Set to 0 to disable the confidence gate.
RETRIEVAL_CONFIDENCE_THRESHOLD=0.2

# ===============================
# Observability & Tracing
# ===============================
ENABLE_TRACING=false
TRACE_SAMPLE_RATE=1.0
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
REQUEST_ID_HEADER=x-request-id